package org.team_alilm.algamja.product.crawler.impl.ably

import org.slf4j.LoggerFactory
import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty
import org.springframework.core.annotation.Order
import org.springframework.stereotype.Component
import org.team_alilm.algamja.common.exception.BusinessException
import org.team_alilm.algamja.common.exception.ErrorCode
import org.team_alilm.algamja.product.crawler.ProductCrawler
import org.team_alilm.algamja.product.crawler.dto.CrawledProduct

/**
 * Ably í•˜ì´ë¸Œë¦¬ë“œ í¬ë¡¤ëŸ¬
 * 1ì°¨: REST API í˜¸ì¶œ (ë¹ ë¥´ê³  íš¨ìœ¨ì )
 * 2ì°¨: Selenium ë°±ì—… (API ì‹¤íŒ¨ ì‹œ ì›¹ í˜ì´ì§€ í¬ë¡¤ë§)
 * 
 * EC2 í™˜ê²½ì—ì„œ Cloudflare ìš°íšŒì™€ ì•ˆì •ì„±ì„ ìœ„í•´ ì„¤ê³„ë¨
 */
@Component
@Order(1) // AblyCrawlerë³´ë‹¤ ìš°ì„ ìˆœìœ„ë¥¼ ë†’ê²Œ ì„¤ì •
@ConditionalOnProperty(name = ["crawler.ably.fallback-to-selenium"], havingValue = "true", matchIfMissing = false)
class AblyHybridCrawler(
    private val ablyCrawler: AblyCrawler,
    private val ablySeleniumCrawler: AblySeleniumCrawler
) : ProductCrawler {

    private val log = LoggerFactory.getLogger(javaClass)

    override fun supports(url: String): Boolean {
        // ë‘ í¬ë¡¤ëŸ¬ ì¤‘ í•˜ë‚˜ë¼ë„ ì§€ì›í•˜ë©´ true
        return ablyCrawler.supports(url) || ablySeleniumCrawler.supports(url)
    }

    override fun normalize(url: String): String {
        // ê¸°ë³¸ì ìœ¼ë¡œ API í¬ë¡¤ëŸ¬ì˜ ì •ê·œí™” ì‚¬ìš©
        return ablyCrawler.normalize(url)
    }

    override fun fetch(url: String): CrawledProduct {
        val startTime = System.currentTimeMillis()
        
        log.info("Starting hybrid crawling for URL: {}", url)
        
        // 1ì°¨ ì‹œë„: REST API í¬ë¡¤ë§
        try {
            log.debug("Attempting primary crawling with REST API...")
            val result = ablyCrawler.fetch(url)
            
            val duration = System.currentTimeMillis() - startTime
            log.info("âœ… Primary API crawling successful for URL: {} in {}ms", url, duration)
            return result
            
        } catch (e: BusinessException) {
            log.warn("âŒ Primary API crawling failed for URL: {}, error: {}", url, e.message)
            log.debug("API crawling exception details", e)
            
            // íŠ¹ì • ì—ëŸ¬ ì½”ë“œì— ëŒ€í•´ì„œë§Œ Selenium ë°±ì—… ì‹œë„
            if (e.errorCode == ErrorCode.CRAWLER_INVALID_RESPONSE) {
                return attemptSeleniumFallback(url, startTime)
            } else {
                throw e
            }
            
        } catch (e: Exception) {
            log.warn("âŒ Primary API crawling failed with unexpected error for URL: {}, error: {}", url, e.message)
            log.debug("Unexpected API crawling exception details", e)
            return attemptSeleniumFallback(url, startTime)
        }
    }

    private fun attemptSeleniumFallback(url: String, startTime: Long): CrawledProduct {
        log.info("ğŸ”„ Attempting fallback crawling with Selenium...")
        
        try {
            val result = ablySeleniumCrawler.fetch(url)
            
            val duration = System.currentTimeMillis() - startTime
            log.info("âœ… Fallback Selenium crawling successful for URL: {} in {}ms", url, duration)
            return result
            
        } catch (e: Exception) {
            val duration = System.currentTimeMillis() - startTime
            log.error("âŒ Both primary and fallback crawling failed for URL: {} after {}ms", url, duration, e)
            
            // ë§ˆì§€ë§‰ìœ¼ë¡œ ì›ë³¸ ì—ëŸ¬ë¥¼ ê·¸ëŒ€ë¡œ ë˜ì§€ê±°ë‚˜ ì¼ë°˜ì ì¸ í¬ë¡¤ë§ ì‹¤íŒ¨ ì—ëŸ¬ë¥¼ ë˜ì§
            if (e is BusinessException) {
                throw e
            } else {
                throw BusinessException(ErrorCode.CRAWLER_INVALID_RESPONSE)
            }
        }
    }
}